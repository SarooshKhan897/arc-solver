"""Prompt generation for the solver with enhanced perception integration."""

import json
from typing import Any

import numpy as np

from src.utils.grid import grid_to_text
from src.perception.analyzer import (
    analyze_example,
    analyze_grid,
    analyze_task,
    GridAnalysis,
    TransformAnalysis,
    ExampleAnalysis,
    TaskAnalysis,
)
from src.perception.perceiver import format_hypotheses_for_solver


# =============================================================================
# System Prompt (matches notebook HYPOTHESIZER_SYSTEM)
# =============================================================================

SOLVER_SYSTEM = """
You solve ARC-AGI puzzles by discovering the transformation rule from input-output examples, then implementing it as Python code. Return a single transform function that can be used to transform any input grid to the corresponding output grid as def transform(grid: np.ndarray) -> np.ndarray: ...

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HARD CONSTRAINTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GRID SPEC:
- 2D numpy arrays, 1Ã—1 to 30Ã—30
- Colors are integers 0-9 ONLY:
    0=black  1=blue   2=red     3=green   4=yellow
    5=gray   6=magenta 7=orange  8=azure   9=maroon
- âš ï¸ ANY value outside 0-9 = immediate failure

OUTPUT SPEC:
- Single function: def transform(grid: np.ndarray) -> np.ndarray
- Libraries: numpy, scipy.ndimage only
- Return: 2D array with integer dtype
- NO test code, NO examples, NO __main__ â€” function only

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COGNITIVE WORKFLOW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PHASE 1: OBSERVE (per example)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
For EACH inputâ†’output pair, document:
  â€¢ Dimensions: same, scaled, cropped, or dynamically computed?
  â€¢ Colors: which appear, disappear, change, or remain fixed?
  â€¢ Objects: what are the discrete "things"? (connected regions, shapes, lines)
  â€¢ Spatial relationships: distances, alignment, containment, symmetry?
  â€¢ What information in the input determines the output?

PHASE 2: HYPOTHESIZE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ask yourself:
  â€¢ What is the SIMPLEST rule that explains ALL examples?
  â€¢ What does the output "know" that only the input could "tell" it?
  â€¢ Is the transformation:
      - Per-pixel (local neighborhood operation)
      - Per-object (requires identifying discrete objects)
      - Global (whole-grid geometric transform)
      - Compositional (sequence of simpler steps)
  â€¢ Does one object serve as a template/reference for another?

PHASE 3: VERIFY EXHAUSTIVELY  
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âš ï¸ BEFORE writing ANY code, mentally execute your rule on EVERY example:
  âœ“ Does output size match exactly?
  âœ“ Does every pixel match?
  âœ“ Are there ANY exceptions?
If ANY mismatch â†’ revise hypothesis. Do not proceed until all examples pass.

PHASE 4: IMPLEMENT DEFENSIVELY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â€¢ Handle edge cases: empty masks, objects at boundaries, no matches
  â€¢ Clamp coordinates: use np.clip() for safety
  â€¢ Verify output shape matches expected dimensions
  â€¢ Cast output to int dtype

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
KEY HEURISTICS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OUTPUT SIZE PATTERNS:
  â€¢ Same as input â†’ in-place transformation or overlay
  â€¢ Constant across examples â†’ extract fixed-size pattern
  â€¢ Scaled by NÃ— â†’ upscale, tile, or repeat
  â€¢ Smaller â†’ crop to bounding box, extract subregion, or select
  â€¢ Varies with content â†’ size = f(object_count, object_size, grid_property)

COLOR MAPPING:
  â€¢ Track which input colors map to which output colors (1:1, N:1, or 1:N)
  â€¢ Colors may: stay fixed, swap, disappear, appear new, or transform conditionally
  â€¢ Color can encode role: marker vs target vs fill vs border
  â€¢ Same shape + different color â†’ color determines behavior
  â€¢ Output may use colors not present in input (new color = computed result)
  â€¢ Background in input may become meaningful in output (figure-ground reversal)

OBJECT ROLES:
  â€¢ Unique object â†’ often the "special" one (template, target, rule-giver)
  â€¢ Repeated objects â†’ often operands to transform uniformly
  â€¢ Smallest object â†’ may be a marker, seed, or template
  â€¢ Largest object â†’ may be a container, canvas, or frame
  â€¢ Object with unique color â†’ may indicate special behavior

IMPLICIT STRUCTURE:
  â€¢ Regular spacing â†’ hidden grid; cells may contain patterns
  â€¢ Separating lines (full row/column of one color) â†’ dividers between regions
  â€¢ Symmetry (partial) â†’ complete the symmetry
  â€¢ Repeating motif â†’ tile or extend the pattern

INFORMATION FLOW:
  â€¢ Color determines behavior (if red â†’ do X, if blue â†’ do Y)
  â€¢ Position determines behavior (corners, edges, center are special)
  â€¢ Shape determines behavior (squares vs lines vs irregular)
  â€¢ Count determines output (n objects â†’ nÃ—n grid, etc.)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PATTERN TAXONOMY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Reference this catalog when forming hypotheses. Most ARC tasks combine 1-3 of these.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
A. GEOMETRIC TRANSFORMATIONS (whole-grid or per-object)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ROTATION_90        â”‚ Rotate grid/object 90Â° clockwise: np.rot90(grid, k=-1)
ROTATION_180       â”‚ Rotate 180Â°: np.rot90(grid, k=2)
ROTATION_270       â”‚ Rotate 270Â° clockwise (90Â° counter-clockwise): np.rot90(grid, k=1)
FLIP_HORIZONTAL    â”‚ Mirror leftâ†”right: np.fliplr(grid)
FLIP_VERTICAL      â”‚ Mirror topâ†”bottom: np.flipud(grid)
FLIP_DIAGONAL      â”‚ Transpose across main diagonal: grid.T
FLIP_ANTIDIAGONAL  â”‚ Transpose across anti-diagonal: np.flipud(grid.T)
TRANSLATE          â”‚ Shift grid/object by (dy, dx), wrap or clip at edges
SCALE_UP           â”‚ Enlarge by integer factor (each pixel becomes NxN block)
SCALE_DOWN         â”‚ Shrink by factor (NxN blocks become single pixel, via mode/max/min)
SHEAR              â”‚ Skew rows/columns by offset pattern

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
B. TILING & REPETITION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TILE_REPEAT        â”‚ Repeat grid NxM times: np.tile(grid, (N, M))
TILE_MIRROR        â”‚ Tile with alternating flips (wallpaper pattern)
TILE_ROTATE        â”‚ Tile with 90Â° rotations in each quadrant
STACK_HORIZONTAL   â”‚ Concatenate grids side-by-side: np.hstack([a, b])
STACK_VERTICAL     â”‚ Concatenate grids top-to-bottom: np.vstack([a, b])
INTERLEAVE_ROWS    â”‚ Alternate rows from two sources: output[::2], output[1::2]
INTERLEAVE_COLS    â”‚ Alternate columns from two sources
SPIRAL_TILE        â”‚ Arrange copies in spiral or radial pattern
FRAME_REPEAT       â”‚ Add concentric frames/borders around core pattern

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
C. CROPPING & EXTRACTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CROP_TO_CONTENT    â”‚ Remove all-background rows/cols, output = minimal bounding box
CROP_TO_OBJECT     â”‚ Extract single object's bounding box
CROP_TO_REGION     â”‚ Extract rectangular region defined by markers/colors
EXTRACT_UNIQUE     â”‚ Pull out the one object that differs from others
EXTRACT_BY_COLOR   â”‚ Extract all pixels/objects of specific color
EXTRACT_BY_SIZE    â”‚ Extract object(s) matching size criteria (largest, smallest, Nth)
EXTRACT_BY_SHAPE   â”‚ Extract object(s) matching shape signature
EXTRACT_TEMPLATE   â”‚ Identify and extract the "reference" pattern used elsewhere
EXTRACT_BORDER     â”‚ Output only the outermost edge pixels of grid/object
EXTRACT_INTERIOR   â”‚ Output only non-border pixels (hollow out the frame)
SAMPLE_PIXELS      â”‚ Extract pixels at regular intervals (every Nth row/col)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
D. EXTENSION & EXPANSION  
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXTEND_LINES       â”‚ Continue lines/rays until grid edge or collision
EXTEND_PATTERN     â”‚ Propagate repeating pattern to fill region
EXTEND_BORDER      â”‚ Add N layers of border pixels (solid or patterned)
PAD_TO_SIZE        â”‚ Add background padding to reach target dimensions
GROW_OBJECT        â”‚ Expand object by 1 pixel in all directions (dilation)
GROW_DIRECTIONAL   â”‚ Expand object in specific direction only (right, down, etc.)
FILL_TO_EDGE       â”‚ Extend object/color until it hits grid boundary
EXTRUDE            â”‚ Repeat pattern along an axis (2Dâ†’2D stretch)
CONNECT_ENDPOINTS  â”‚ Draw lines between matching markers/colors

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
E. FILL OPERATIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FLOOD_FILL         â”‚ Fill connected region with color (paint bucket)
FILL_ENCLOSED      â”‚ Fill regions completely surrounded by boundary color
FILL_BACKGROUND    â”‚ Replace all background (0) with specified color
FILL_HOLES         â”‚ Fill small enclosed gaps within objects
FILL_BOUNDING_BOX  â”‚ Fill rectangular hull of object with solid color
FILL_CONVEX_HULL   â”‚ Fill convex hull of object's pixels
FILL_BETWEEN       â”‚ Fill space between two objects/lines
FILL_ROW           â”‚ Fill entire row(s) based on trigger condition
FILL_COL           â”‚ Fill entire column(s) based on trigger condition
FILL_CHECKERBOARD  â”‚ Fill region with alternating pattern
GRADIENT_FILL      â”‚ Fill with incrementing color values (1,2,3,...)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
F. COLOR OPERATIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COLOR_SWAP         â”‚ Exchange two colors: Aâ†”B throughout grid
COLOR_REPLACE      â”‚ Replace all A with B (one-way): grid[grid==A] = B
COLOR_MAP          â”‚ Apply mapping dict: {old: new} for multiple colors
COLOR_INVERT       â”‚ Swap foreground/background roles
COLOR_CYCLE        â”‚ Rotate colors by offset: (color + k) % N
COLOR_BY_POSITION  â”‚ Assign color based on (row, col) properties
COLOR_BY_SIZE      â”‚ Assign color based on object size ranking
COLOR_BY_COUNT     â”‚ Color encodes frequency/count information
COLOR_NORMALIZE    â”‚ Map all non-background to single foreground color
COLOR_FROM_PALETTE â”‚ Reference object defines color mapping for others
MAJORITY_COLOR     â”‚ Replace region with its most common color
BOUNDARY_COLOR     â”‚ Color pixels differently if on object boundary

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
G. OBJECT-LEVEL OPERATIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COPY_OBJECT        â”‚ Duplicate object to new location(s)
MOVE_OBJECT        â”‚ Relocate object by offset or to absolute position
MOVE_TO_MARKER     â”‚ Move object to position indicated by marker pixel
ALIGN_OBJECTS      â”‚ Align objects by edge, center, or common feature
SORT_OBJECTS       â”‚ Reorder objects by size, color, position, or shape
STACK_OBJECTS      â”‚ Overlay objects (later overwrites earlier)
MERGE_OBJECTS      â”‚ Combine touching/nearby objects into one
SPLIT_OBJECT       â”‚ Divide object into components (by color, connectivity)
DELETE_OBJECT      â”‚ Remove object(s) matching criteria (size, color, etc.)
KEEP_OBJECT        â”‚ Keep only object(s) matching criteria, delete rest
MIRROR_OBJECT      â”‚ Create reflected copy (left, right, above, below)
CLONE_PATTERN      â”‚ Stamp template object at multiple locations
CENTER_OBJECT      â”‚ Move object to grid center
SNAP_TO_GRID       â”‚ Align object to grid lines (quantize position)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
H. CONTAINMENT & ENCLOSURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DRAW_BOUNDING_BOX  â”‚ Draw rectangle around object's extent
DRAW_FRAME         â”‚ Add 1-pixel border around object (touching edges)
DRAW_ENCLOSURE     â”‚ Draw minimal enclosing shape (rectangle, convex hull)
OUTLINE_OBJECT     â”‚ Replace filled object with just its perimeter
HOLLOW_OUT         â”‚ Remove interior, keep only boundary pixels
ENCLOSE_WITH_COLOR â”‚ Surround object with specific color border
FRAME_GRID         â”‚ Add border around entire grid
NESTED_FRAMES      â”‚ Create concentric rectangular frames
BRIDGE_GAPS        â”‚ Connect nearby objects with line/fill

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
I. MASKING & OVERLAY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
APPLY_MASK         â”‚ Use binary mask to select pixels: output = grid * mask
MASK_BY_COLOR      â”‚ Create mask where color == C
MASK_BY_OBJECT     â”‚ Create mask for specific object's footprint
MASK_INVERT        â”‚ Swap masked/unmasked regions
OVERLAY_TEMPLATE   â”‚ Stamp template onto grid at marked positions
OVERLAY_BLEND      â”‚ Combine two grids (non-zero overwrites)
PAINT_THROUGH_MASK â”‚ Apply color/pattern only where mask is true
COMPOSITE          â”‚ Layer multiple grids with priority rules
XOR_GRIDS          â”‚ Output differs where inputs differ
AND_GRIDS          â”‚ Output non-zero only where both inputs non-zero
DIFFERENCE         â”‚ Highlight pixels that changed between grids

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
J. SYMMETRY OPERATIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COMPLETE_SYMMETRY  â”‚ Fill missing pixels to achieve mirror symmetry
RESTORE_SYMMETRY   â”‚ Fix "broken" pixels that violate existing symmetry
REFLECT_TO_FILL    â”‚ Use one half to complete the other half
ROTATIONAL_SYMMETRYâ”‚ Complete pattern with 90Â°/180Â° rotational copies
DETECT_AXIS        â”‚ Find axis of symmetry, use to guide completion
SYMMETRIZE         â”‚ Force exact symmetry by averaging/voting

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
K. PATTERN COMPLETION & REPAIR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COMPLETE_SEQUENCE  â”‚ Extend repeating sequence (1,2,3,1,2,3,1,2,?)
REPAIR_PATTERN     â”‚ Fix corrupted pixels in otherwise regular pattern
INPAINT            â”‚ Fill marked region based on surrounding context
EXTRAPOLATE        â”‚ Continue observed progression beyond examples
INTERPOLATE        â”‚ Fill gaps in sequence (1,?,3 â†’ 1,2,3)
DENOISE            â”‚ Remove isolated pixels that break pattern
MAJORITY_VOTE      â”‚ Each cell becomes local majority color (smoothing)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
L. COUNTING & ARITHMETIC
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COUNT_OBJECTS      â”‚ Output encodes number of objects as grid size/color
COUNT_COLORS       â”‚ Output encodes color frequency information
COUNT_PIXELS       â”‚ Output size/value based on pixel count
SIZE_COMPARISON    â”‚ Output depends on comparing object sizes
ARITHMETIC_COLOR   â”‚ Output color = f(input colors): sum, diff, max, min
MODULAR_ARITHMETIC â”‚ Color values computed modulo N
BINARY_ENCODING    â”‚ Grid represents binary number or logical formula

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
M. SORTING & ORDERING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SORT_ROWS          â”‚ Reorder rows by some criterion (sum, first color, etc.)
SORT_COLS          â”‚ Reorder columns by criterion
SORT_BY_SIZE       â”‚ Arrange objects smallâ†’large or largeâ†’small
SORT_BY_COLOR      â”‚ Arrange objects by color value
GRAVITY_DROP       â”‚ Objects fall toward edge (down, left, etc.)
GRAVITY_FLOAT      â”‚ Objects rise toward edge (up, right, etc.)
COMPACT            â”‚ Remove gaps, push objects together
JUSTIFY_LEFT       â”‚ Align all objects to left edge
JUSTIFY_TOP        â”‚ Align all objects to top edge

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
N. CONDITIONAL & LOGIC
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
IF_ENCLOSED        â”‚ Transform only enclosed/contained objects
IF_TOUCHES_EDGE    â”‚ Transform objects touching grid boundary
IF_LARGEST         â”‚ Apply operation to largest object only
IF_COLOR_MATCH     â”‚ Apply operation where color condition met
IF_NEIGHBOR        â”‚ Transform based on adjacent cell colors
IF_ISOLATED        â”‚ Transform objects not touching others
IF_CONNECTED       â”‚ Transform objects connected to marker
IF_SYMMETRIC       â”‚ Different handling for symmetric vs asymmetric
IF_ABOVE_THRESHOLD â”‚ Apply when count/size exceeds threshold
SWITCH_ON_COUNT    â”‚ Different output based on object count

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
O. REFERENCE & TEMPLATE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
USE_AS_TEMPLATE    â”‚ One object defines pattern applied to others
USE_AS_PALETTE     â”‚ One object defines color mapping
USE_AS_STENCIL     â”‚ One object defines shape, another defines fill
USE_AS_KEY         â”‚ Small grid maps to transformation parameters
LOOKUP_TABLE       â”‚ Reference grid maps inputâ†’output values
MATCH_AND_REPLACE  â”‚ Find pattern, replace with different pattern
TEMPLATE_MATCHING  â”‚ Find where template appears, mark or transform

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
P. CONNECTIVITY & TOPOLOGY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CONNECT_SAME_COLOR â”‚ Draw lines between objects of same color
SHORTEST_PATH      â”‚ Draw path between marked points
FLOOD_REACH        â”‚ Mark all cells reachable from origin
SEPARATE_COMPONENTSâ”‚ Assign different colors to disconnected regions
COMPONENT_LABEL    â”‚ Number each connected component
FIND_BRIDGES       â”‚ Identify pixels whose removal disconnects regions
CLOSE_GAPS         â”‚ Connect nearly-touching objects (morphological close)
OPEN_GAPS          â”‚ Separate barely-touching objects (morphological open)
SKELETONIZE        â”‚ Reduce object to 1-pixel-wide skeleton
THICKEN            â”‚ Expand skeleton back to full object

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Q. PROJECTION & AGGREGATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PROJECT_HORIZONTAL â”‚ Collapse each row to single value (OR, AND, MAX, etc.)
PROJECT_VERTICAL   â”‚ Collapse each column to single value
PROJECT_TO_EDGE    â”‚ "Shadow" cast from objects onto edge
HISTOGRAM          â”‚ Output represents frequency distribution
AGGREGATE_BY_COLOR â”‚ Combine all objects of same color
AGGREGATE_BY_REGIONâ”‚ Summarize each rectangular region
REDUCE_TO_SIGNATUREâ”‚ Output is minimal representation of input pattern

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COMMON COMPOSITIONS (multi-step)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EXTRACT â†’ COLOR    â”‚ Pull out object, recolor it
MASK â†’ FILL        â”‚ Create mask from pattern, fill masked region  
FIND â†’ COPY        â”‚ Locate template, copy to marked positions
SEGMENT â†’ SORT     â”‚ Identify objects, reorder by property
CROP â†’ TILE        â”‚ Extract core pattern, tile to fill output
DETECT â†’ COMPLETE  â”‚ Find partial symmetry, complete it
COUNT â†’ RESIZE     â”‚ Count something, output dimensions = count
COMPARE â†’ MARK     â”‚ Find differences between objects, highlight them

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COMMON MISTAKES TO AVOID
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âŒ Overfitting: rule works on one example but fails others
âŒ Off-by-one: r_max+1 for slicing, range(1, n+1) for labels
âŒ Coordinate confusion: numpy uses (row, col) not (x, y)
âŒ Boundary errors: objects at edge may be clipped or wrap incorrectly
âŒ Hardcoding: values that should be computed from input
âŒ Empty case: what if no objects found? (return grid.copy() or empty)
âŒ Wrong connectivity: 4-connected vs 8-connected components
âŒ Assuming fixed counts: object count may vary between examples
âŒ Ignoring relative position: transform may depend on where objects are

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DETERMINISTIC TIE-BREAKING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

When multiple candidates are equivalent, select by priority:
  1. Top-most (minimum row index)
  2. Left-most (minimum column index)
  3. Smallest area (fewest pixels)
  4. Smallest color value

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
NUMPY PRIMITIVES REFERENCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# GRID BASICS
H, W = grid.shape                          # Dimensions
out = np.zeros((H, W), dtype=int)          # Empty grid
out = np.full((H, W), fill_value=c)        # Filled with color c
out = grid.copy()                          # Copy (always use for mutation)
out = np.zeros_like(grid)                  # Same shape, all zeros

# GEOMETRIC TRANSFORMS
np.rot90(grid, k=1)                        # 90Â° CCW (k=1,2,3)
np.rot90(grid, k=-1)                       # 90Â° CW
np.flip(grid, axis=0)                      # Flip vertical
np.flip(grid, axis=1)                      # Flip horizontal
grid.T                                     # Transpose

# SLICING
grid[r, c]                                 # Single cell
grid[r1:r2, c1:c2]                         # Subgrid [r1,r2) Ã— [c1,c2)
grid[r, :]                                 # Row r
grid[:, c]                                 # Column c
grid[::2, ::2]                             # Stride 2 (downsample)

# MASKS & BOOLEAN INDEXING
mask = (grid == color)                     # Where equals color
mask = (grid != 0)                         # Non-background
rows, cols = np.where(mask)                # Coordinates where True
coords = np.argwhere(mask)                 # Array of [r, c] pairs
grid[mask] = new_color                     # Set masked cells
np.any(mask)                               # Any True?
np.sum(mask)                               # Count True

# COLOR OPERATIONS
colors = np.unique(grid)                   # Unique colors
colors, counts = np.unique(grid, return_counts=True)
out = np.where(grid == old, new, grid)     # Replace oldâ†’new
np.isin(grid, [1, 2, 3])                   # Mask where in list

# SCALING & TILING
np.repeat(np.repeat(grid, n, axis=0), n, axis=1)  # Upscale nÃ—
np.kron(grid, np.ones((n, n), dtype=int))         # Upscale nÃ— (alt)
np.tile(grid, (r, c))                             # Tile rÃ—c times
grid[::n, ::n]                                    # Downsample nÃ—

# BOUNDING BOX
rows, cols = np.where(grid != 0)
if len(rows) > 0:
    r_min, r_max = rows.min(), rows.max()
    c_min, c_max = cols.min(), cols.max()
    cropped = grid[r_min:r_max+1, c_min:c_max+1]  # +1 for inclusive

# PADDING & STACKING
np.pad(grid, pad_width=1, constant_values=0)    # Pad all sides
np.pad(grid, ((t,b), (l,r)), constant_values=0) # Asymmetric
np.vstack([a, b])                               # Stack vertically
np.hstack([a, b])                               # Stack horizontally

# CONNECTED COMPONENTS (scipy.ndimage)
from scipy import ndimage

# 4-connectivity (orthogonal neighbors only)
labeled, n = ndimage.label(grid != 0)

# 8-connectivity (include diagonals)
struct = ndimage.generate_binary_structure(2, 2)
labeled, n = ndimage.label(grid != 0, structure=struct)

# Get component k (labels are 1-indexed)
mask_k = (labeled == k)
coords_k = np.argwhere(labeled == k)

# Morphology
ndimage.binary_dilation(mask)              # Expand
ndimage.binary_erosion(mask)               # Shrink
ndimage.binary_fill_holes(mask)            # Fill interior

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TYPE SAFETY & ERROR PREVENTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ GRID VALUES MUST ALWAYS BE INTEGERS (not strings, floats, or mixed)

DEFENSIVE PATTERNS:
# Always cast to int when creating output
out = np.zeros((H, W), dtype=int)
out = grid.astype(int)

# When assigning values, ensure int type
out[r, c] = int(color)

# Safe color replacement
out = np.where(grid == old_color, new_color, grid).astype(int)

# Final output safety â€” ALWAYS end transform() with:
return out.astype(int)

NEVER DO:
  âŒ grid[r, c] = "1"           # String instead of int
  âŒ colors = ["0", "1", "2"]   # String list
  âŒ if color > "0":            # Comparing to string
  âŒ out = grid / 2             # Creates floats

ALWAYS DO:
  âœ“ grid[r, c] = 1              # Integer literal
  âœ“ colors = [0, 1, 2]          # Integer list
  âœ“ if color > 0:               # Comparing to int
  âœ“ out = grid // 2             # Integer division
  âœ“ return out.astype(int)      # Explicit cast on return   
"""


# =============================================================================
# Formatting Helpers for Perception Data
# =============================================================================

def _format_objects_compact(objects: list[dict[str, Any]], max_objects: int = 8) -> str:
    """Format detected objects in a compact, decision-relevant way."""
    if not objects:
        return "  (no objects detected)"
    
    lines = []
    for i, obj in enumerate(objects[:max_objects]):
        obj_id = obj.get('id', i + 1)
        color = obj.get('color', 'unknown')
        shape = obj.get('shape', 'unknown')
        size = obj.get('size', '?')
        pos = obj.get('position', '')
        special = obj.get('special', '')
        
        desc = f"  #{obj_id}: {color} {shape} (size={size})"
        if pos:
            desc += f" @ {pos}"
        if special:
            desc += f" â˜…{special}"
        lines.append(desc)
    
    if len(objects) > max_objects:
        lines.append(f"  ... and {len(objects) - max_objects} more objects")
    
    return '\n'.join(lines)


def _format_relationships(relationships: list[dict[str, Any]], max_rels: int = 6) -> str:
    """Format object relationships for decision-making."""
    if not relationships:
        return "  (no relationships detected)"
    
    lines = []
    for rel in relationships[:max_rels]:
        rel_type = rel.get('type', 'unknown')
        
        if rel_type == 'adjacent':
            direction = rel.get('direction', '')
            lines.append(f"  â€¢ Object {rel.get('obj1')} â†” Object {rel.get('obj2')} ({rel_type}, {direction})")
        elif rel_type == 'contained':
            lines.append(f"  â€¢ Object {rel.get('inner')} inside Object {rel.get('outer')}")
        elif rel_type == 'aligned':
            objs = rel.get('objects', [])
            axis = rel.get('axis', '')
            lines.append(f"  â€¢ Objects {objs} aligned {axis}ly")
        else:
            lines.append(f"  â€¢ {rel}")
    
    if len(relationships) > max_rels:
        lines.append(f"  ... and {len(relationships) - max_rels} more relationships")
    
    return '\n'.join(lines)


def _format_patterns_and_features(
    global_patterns: list[str] | None,
    notable_features: list[str] | None,
) -> str:
    """Format global patterns and notable features."""
    lines = []
    
    if global_patterns:
        lines.append("  Patterns:")
        for p in global_patterns[:5]:
            lines.append(f"    â€¢ {p}")
    
    if notable_features:
        lines.append("  Notable:")
        for f in notable_features[:5]:
            lines.append(f"    â€¢ {f}")
    
    return '\n'.join(lines) if lines else "  (none detected)"


def _format_delta(delta: dict[str, Any]) -> str:
    """Format transformation delta in a decision-focused way."""
    lines = []
    
    summary = delta.get('summary', '')
    if summary:
        lines.append(f"  Summary: {summary}")
    
    obj_changes = delta.get('object_changes', [])
    if obj_changes:
        lines.append("  Object Changes:")
        for change in obj_changes[:5]:
            lines.append(f"    â€¢ {change}")
    
    color_changes = delta.get('color_changes', [])
    if color_changes:
        lines.append("  Color Changes:")
        for change in color_changes[:3]:
            lines.append(f"    â€¢ {change}")
    
    structural = delta.get('structural_changes', [])
    if structural:
        lines.append("  Structural:")
        for s in structural[:3]:
            lines.append(f"    â€¢ {s}")
    
    constants = delta.get('constants', [])
    if constants:
        lines.append(f"  Constants: {', '.join(constants)}")
    
    return '\n'.join(lines) if lines else "  (no delta computed)"


def _format_hypotheses_section(hypotheses: list[dict[str, Any]], key_insight: str | None = None) -> str:
    """Format transformation hypotheses with decision priority indicators."""
    if not hypotheses:
        return ""
    
    lines = [
        "",
        "â•”" + "â•" * 58 + "â•—",
        "â•‘  ğŸ§  TRANSFORMATION HYPOTHESES (Use These for Decision)      â•‘",
        "â•š" + "â•" * 58 + "â•",
    ]
    
    if key_insight:
        lines.append(f"\nğŸ’¡ KEY INSIGHT: {key_insight}")
    
    lines.append("")
    
    for h in hypotheses[:5]:
        rank = h.get("rank", "?")
        conf = h.get("confidence", "?")
        rule = h.get("rule", "No rule specified")
        evidence = h.get("evidence", "")
        
        # Confidence indicator
        conf_icon = "ğŸŸ¢" if conf == "HIGH" else "ğŸŸ¡" if conf == "MEDIUM" else "ğŸ”´"
        
        lines.append(f"  {conf_icon} #{rank} [{conf}]")
        lines.append(f"     Rule: {rule}")
        if evidence:
            # Truncate long evidence
            ev_short = evidence[:150] + "..." if len(evidence) > 150 else evidence
            lines.append(f"     Evidence: {ev_short}")
        lines.append("")
    
    lines.append("  âš ï¸ VERIFY: Before coding, mentally check your chosen hypothesis against ALL examples!")
    
    return '\n'.join(lines)


def _format_observations(observations: dict[str, Any]) -> str:
    """Format task-level observations from perceiver."""
    if not observations:
        return ""
    
    lines = ["", "ğŸ“‹ PERCEIVER OBSERVATIONS:"]
    
    common_input = observations.get('common_input_features', [])
    if common_input:
        lines.append(f"  Input patterns: {', '.join(common_input[:4])}")
    
    common_output = observations.get('common_output_features', [])
    if common_output:
        lines.append(f"  Output patterns: {', '.join(common_output[:4])}")
    
    size_pattern = observations.get('size_pattern', '')
    if size_pattern:
        lines.append(f"  Size behavior: {size_pattern}")
    
    color_changes = observations.get('color_changes', '')
    if color_changes:
        lines.append(f"  Color behavior: {color_changes}")
    
    return '\n'.join(lines)


def _format_symmetry(has_symmetry: dict[str, bool]) -> str:
    """Format symmetry information compactly."""
    active = [k for k, v in has_symmetry.items() if v]
    if not active:
        return "none"
    return ', '.join(active)


def _infer_likely_patterns(task_analysis: TaskAnalysis) -> list[str]:
    """Infer likely pattern categories based on task analysis."""
    patterns = []
    
    # Check size behavior
    if task_analysis.consistent_size_preservation:
        patterns.append("IN-PLACE (same size throughout)")
    else:
        # Check if size changes consistently
        size_changes = []
        for ex in task_analysis.train_examples:
            t = ex.transform_analysis
            if t.size_change_percent > 50:
                size_changes.append("GROW")
            elif t.size_change_percent < -50:
                size_changes.append("SHRINK")
        if size_changes:
            patterns.append(f"SIZE CHANGE ({set(size_changes)})")
    
    # Check color behavior
    if task_analysis.consistent_color_preservation:
        patterns.append("COLORS PRESERVED")
    else:
        for ex in task_analysis.train_examples:
            t = ex.transform_analysis
            if t.new_colors_introduced:
                patterns.append(f"NEW COLORS ADDED")
                break
    
    # Check shape count
    if task_analysis.consistent_shape_count:
        patterns.append("SHAPE COUNT PRESERVED")
    
    return patterns


# =============================================================================
# Main Prompt Generation
# =============================================================================

def generate_prompt(
    task_data: dict[str, Any],
    perceptions: list[dict[str, Any]] | None = None,
    deltas: list[dict[str, Any]] | None = None,
    test_perception: dict[str, Any] | list[dict[str, Any]] | None = None,
    hypotheses: list[dict[str, Any]] | None = None,
    observations: dict[str, Any] | None = None,
    key_insight: str | None = None,
    feedback: str | None = None,
    include_analysis: bool = True,
) -> str:
    """
    Generate a rich prompt for the solver with enhanced perception integration.

    Args:
        task_data: Task with 'train' and 'test' keys
        perceptions: Per-example perceptions (objects, relationships, patterns)
        deltas: Per-example transformation deltas
        test_perception: Perception(s) of test input(s)
        hypotheses: Ranked transformation hypotheses from perceiver
        observations: Task-level observations from perceiver
        key_insight: The key insight about the puzzle
        feedback: Optional feedback from previous failed attempt
        include_analysis: Whether to include detailed grid analysis

    Returns:
        The complete prompt string
    """
    parts = []
    train_examples = task_data['train']
    
    # Perform task-level analysis
    task_analysis = analyze_task(task_data, "current") if include_analysis else None

    # =================================================================
    # SECTION 1: Decision Support Summary (Top of Prompt)
    # =================================================================
    parts.append("â•”" + "â•" * 58 + "â•—")
    parts.append("â•‘          ARC PUZZLE - TRANSFORMATION TASK                â•‘")
    parts.append("â•š" + "â•" * 58 + "â•")
    
    # Quick summary box for fast decision making
    parts.append("\nâ”Œâ”€ QUICK SUMMARY â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    parts.append(f"â”‚  Training Examples: {len(train_examples)}")
    parts.append(f"â”‚  Test Cases: {len(task_data['test'])}")
    
    if task_analysis:
        likely = _infer_likely_patterns(task_analysis)
        if likely:
            parts.append(f"â”‚  Likely Patterns: {', '.join(likely[:3])}")
        if task_analysis.common_hints:
            parts.append(f"â”‚  Common Transforms: {', '.join(task_analysis.common_hints[:3])}")
    
    # Size pattern summary
    size_info = []
    for idx, pair in enumerate(train_examples):
        inp = np.array(pair['input'])
        out = np.array(pair['output'])
        size_info.append(f"Ex{idx+1}: {inp.shape}â†’{out.shape}")
    parts.append(f"â”‚  Size Changes: {' | '.join(size_info)}")
    parts.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    # =================================================================
    # SECTION 2: Transformation Hypotheses (If Available)
    # =================================================================
    if hypotheses:
        parts.append(_format_hypotheses_section(hypotheses, key_insight))
    
    if observations:
        parts.append(_format_observations(observations))

    # =================================================================
    # SECTION 3: Training Examples with Integrated Analysis
    # =================================================================
    parts.append("\n" + "=" * 60)
    parts.append("TRAINING EXAMPLES")
    parts.append("=" * 60)

    for idx, pair in enumerate(train_examples):
        inp = np.array(pair['input'])
        out = np.array(pair['output'])

        parts.append(f"\n{'â”€'*60}")
        parts.append(f"EXAMPLE {idx + 1} of {len(train_examples)}")
        parts.append(f"{'â”€'*60}")

        # INPUT GRID
        parts.append(f"\nâ”Œâ”€ INPUT ({inp.shape[0]}Ã—{inp.shape[1]}) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        parts.append(grid_to_text(inp))
        
        # Input analysis
        if include_analysis:
            example_analysis = analyze_example(inp, out, idx + 1)
            inp_a = example_analysis.input_analysis
            
            parts.append(f"\n  ğŸ“Š Stats: {inp_a.colors_used} colors | {inp_a.total_shapes} shapes | {inp_a.fill_ratio:.0f}% filled")
            parts.append(f"  ğŸ¨ Palette: {', '.join(inp_a.color_palette)}")
            parts.append(f"  ğŸ”² Background: {inp_a.background_color}")
            
            sym = _format_symmetry(inp_a.has_symmetry)
            if sym != "none":
                parts.append(f"  ğŸ”„ Symmetry: {sym}")
        
        # Input perception (objects, relationships)
        if perceptions and idx < len(perceptions):
            perc = perceptions[idx]
            
            # Handle both nested (input/output) and flat perception formats
            inp_perc = perc.get('input', perc) if 'input' in perc else perc
            
            inp_objects = inp_perc.get('objects', [])
            if inp_objects:
                parts.append(f"\n  ğŸ” DETECTED OBJECTS ({len(inp_objects)}):")
                parts.append(_format_objects_compact(inp_objects))
            
            inp_rels = inp_perc.get('relationships', [])
            if inp_rels:
                parts.append(f"\n  ğŸ”— RELATIONSHIPS:")
                parts.append(_format_relationships(inp_rels))
            
            inp_patterns = inp_perc.get('global_patterns', [])
            inp_features = inp_perc.get('notable_features', [])
            if inp_patterns or inp_features:
                parts.append(f"\n  âœ¨ PATTERNS & FEATURES:")
                parts.append(_format_patterns_and_features(inp_patterns, inp_features))

        # OUTPUT GRID
        parts.append(f"\nâ”Œâ”€ OUTPUT ({out.shape[0]}Ã—{out.shape[1]}) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        parts.append(grid_to_text(out))
        
        # Output analysis
        if include_analysis:
            out_a = example_analysis.output_analysis
            
            parts.append(f"\n  ğŸ“Š Stats: {out_a.colors_used} colors | {out_a.total_shapes} shapes | {out_a.fill_ratio:.0f}% filled")
            parts.append(f"  ğŸ¨ Palette: {', '.join(out_a.color_palette)}")
            
            sym = _format_symmetry(out_a.has_symmetry)
            if sym != "none":
                parts.append(f"  ğŸ”„ Symmetry: {sym}")
        
        # Output perception (if available)
        if perceptions and idx < len(perceptions):
            perc = perceptions[idx]
            out_perc = perc.get('output', {})
            
            out_objects = out_perc.get('objects', [])
            if out_objects:
                parts.append(f"\n  ğŸ” OUTPUT OBJECTS ({len(out_objects)}):")
                parts.append(_format_objects_compact(out_objects))

        # TRANSFORMATION ANALYSIS
        if include_analysis:
            trans_a = example_analysis.transform_analysis
            parts.append(f"\n  âš¡ TRANSFORMATION:")
            
            # Size change
            if trans_a.same_size:
                parts.append(f"     Size: SAME ({inp.shape[0]}Ã—{inp.shape[1]})")
            else:
                parts.append(f"     Size: {inp.shape} â†’ {out.shape} ({trans_a.size_change_percent:+.0f}%)")
            
            # Color changes
            if trans_a.colors_preserved:
                parts.append(f"     Colors: PRESERVED")
            else:
                if trans_a.new_colors:
                    parts.append(f"     Colors Added: {', '.join(trans_a.new_colors)}")
                if trans_a.removed_colors:
                    parts.append(f"     Colors Removed: {', '.join(trans_a.removed_colors)}")
            
            # Shape count
            if trans_a.same_shape_count:
                parts.append(f"     Shapes: PRESERVED ({trans_a.input_shape_count})")
            else:
                parts.append(f"     Shapes: {trans_a.input_shape_count} â†’ {trans_a.output_shape_count}")
            
            # Hints
            if trans_a.hints:
                parts.append(f"     Hints: {', '.join(trans_a.hints[:4])}")

        # Delta (if available)
        if deltas and idx < len(deltas):
            delta = deltas[idx]
            if delta.get('summary') or delta.get('object_changes'):
                parts.append(f"\n  ğŸ“ DELTA:")
                parts.append(_format_delta(delta))

    # =================================================================
    # SECTION 4: Cross-Example Pattern Summary
    # =================================================================
    if include_analysis and task_analysis:
        parts.append("\n" + "=" * 60)
        parts.append("ğŸ” CROSS-EXAMPLE PATTERNS (Decision Factors)")
        parts.append("=" * 60)
        
        # Invariants (things that are always true)
        invariants = []
        if task_analysis.consistent_size_preservation:
            invariants.append("âœ“ Size always preserved")
        if task_analysis.consistent_color_preservation:
            invariants.append("âœ“ Colors always preserved")
        if task_analysis.consistent_shape_count:
            invariants.append("âœ“ Shape count always preserved")
        
        if invariants:
            parts.append("\n  INVARIANTS (must hold in your solution):")
            for inv in invariants:
                parts.append(f"    {inv}")
        
        if task_analysis.common_hints:
            parts.append(f"\n  COMMON HINTS: {', '.join(task_analysis.common_hints)}")
        
        # Inferred patterns
        inferred = _infer_likely_patterns(task_analysis)
        if inferred:
            parts.append(f"\n  INFERRED PATTERN CATEGORIES: {', '.join(inferred)}")

    # =================================================================
    # SECTION 5: Test Input(s)
    # =================================================================
    test_inputs = task_data['test']
    n_tests = len(test_inputs)
    
    parts.append("\n" + "=" * 60)
    parts.append(f"ğŸ¯ TEST INPUT{'S' if n_tests > 1 else ''} ({n_tests} total) - APPLY YOUR RULE HERE")
    parts.append("=" * 60)
    
    for test_idx, test_case in enumerate(test_inputs):
        test_input = np.array(test_case['input'])
        
        if n_tests > 1:
            parts.append(f"\nâ”Œâ”€ TEST {test_idx + 1}/{n_tests} ({test_input.shape[0]}Ã—{test_input.shape[1]}) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        else:
            parts.append(f"\nâ”Œâ”€ TEST INPUT ({test_input.shape[0]}Ã—{test_input.shape[1]}) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        
        parts.append(grid_to_text(test_input))

        # Test input analysis
        if include_analysis:
            test_a = analyze_grid(test_input)
            
            parts.append(f"\n  ğŸ“Š Stats: {test_a.colors_used} colors | {test_a.total_shapes} shapes | {test_a.fill_ratio:.0f}% filled")
            parts.append(f"  ğŸ¨ Palette: {', '.join(test_a.color_palette)}")
            parts.append(f"  ğŸ”² Background: {test_a.background_color}")
            
            sym = _format_symmetry(test_a.has_symmetry)
            if sym != "none":
                parts.append(f"  ğŸ”„ Symmetry: {sym}")

        # Test perception (if available)
        if test_perception:
            # Handle single perception or list
            if isinstance(test_perception, list):
                tp = test_perception[test_idx] if test_idx < len(test_perception) else {}
            else:
                tp = test_perception
            
            tp_objects = tp.get('objects', [])
            if tp_objects:
                parts.append(f"\n  ğŸ” TEST OBJECTS ({len(tp_objects)}):")
                parts.append(_format_objects_compact(tp_objects))
            
            tp_patterns = tp.get('global_patterns', [])
            if tp_patterns:
                parts.append(f"\n  âœ¨ Patterns: {', '.join(tp_patterns[:3])}")

    # =================================================================
    # SECTION 6: Feedback from Previous Attempt (if any)
    # =================================================================
    if feedback:
        parts.append("\n" + "=" * 60)
        parts.append("âš ï¸ FEEDBACK FROM PREVIOUS ATTEMPT - FIX THESE ISSUES")
        parts.append("=" * 60)
        parts.append(feedback)

    # =================================================================
    # SECTION 7: Task Instructions
    # =================================================================
    parts.append("""

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
YOUR TASK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. **STUDY** the training examples above
2. **IDENTIFY** the SINGLE rule that transforms ALL inputs to outputs
3. **VERIFY** your rule mentally on each example before coding
4. **IMPLEMENT** a `transform(grid)` function

PROVIDE:
1. Brief explanation of the pattern (2-3 sentences max)
2. Python code in a ```python block with the `transform` function

Remember:
â€¢ The rule must work for ALL training examples
â€¢ Output grid dimensions must match expected output
â€¢ All values must be integers 0-9
â€¢ Always return out.astype(int)
""")

    return '\n'.join(parts)


def generate_feedback_prompt(
    original_prompt: str,
    code: str,
    feedback_messages: list[str],
    attempt_num: int,
    expected_outputs: list[np.ndarray] | None = None,
    actual_outputs: list[np.ndarray] | None = None,
) -> str:
    """
    Generate a prompt with feedback for retry attempts.

    Args:
        original_prompt: The original task prompt
        code: The code that failed
        feedback_messages: Error messages from the failed attempt
        attempt_num: Current attempt number
        expected_outputs: Expected outputs (if available)
        actual_outputs: What the code actually produced (if available)

    Returns:
        Updated prompt with feedback
    """
    feedback_parts = [
        "",
        "=" * 60,
        f"âš ï¸ ATTEMPT {attempt_num} FAILED - CRITICAL FEEDBACK",
        "=" * 60,
        "",
        "YOUR PREVIOUS CODE:",
        "```python",
        code,
        "```",
        "",
        "ERRORS ENCOUNTERED:",
    ]
    
    for i, msg in enumerate(feedback_messages, 1):
        feedback_parts.append(f"  {i}. {msg}")
    
    # Add visual diff if we have expected vs actual
    if expected_outputs and actual_outputs:
        feedback_parts.append("")
        feedback_parts.append("OUTPUT COMPARISON:")
        for idx, (expected, actual) in enumerate(zip(expected_outputs, actual_outputs)):
            if expected is not None and actual is not None:
                feedback_parts.append(f"\n  Example {idx + 1}:")
                feedback_parts.append(f"    Expected shape: {expected.shape}")
                feedback_parts.append(f"    Your shape:     {actual.shape if hasattr(actual, 'shape') else 'N/A'}")
                
                if hasattr(actual, 'shape') and expected.shape == actual.shape:
                    diff_count = np.sum(expected != actual)
                    total = expected.size
                    feedback_parts.append(f"    Mismatched cells: {diff_count}/{total} ({100*diff_count/total:.1f}%)")
    
    feedback_parts.extend([
        "",
        "INSTRUCTIONS:",
        "  â€¢ Carefully analyze what went wrong",
        "  â€¢ Re-read the training examples",
        "  â€¢ Verify your hypothesis against ALL examples before coding",
        "  â€¢ Provide corrected code",
        "",
    ])

    return original_prompt + '\n'.join(feedback_parts)


# =============================================================================
# Specialized Prompt Variants
# =============================================================================

def generate_minimal_prompt(task_data: dict[str, Any]) -> str:
    """
    Generate a minimal prompt with just grids and basic instructions.
    Useful for faster models or when perception data isn't available.
    """
    parts = []
    train_examples = task_data['train']
    
    parts.append("ARC PUZZLE - Find the transformation rule\n")
    
    for idx, pair in enumerate(train_examples):
        inp = np.array(pair['input'])
        out = np.array(pair['output'])
        
        parts.append(f"Example {idx + 1}:")
        parts.append(f"Input ({inp.shape[0]}Ã—{inp.shape[1]}):")
        parts.append(grid_to_text(inp))
        parts.append(f"Output ({out.shape[0]}Ã—{out.shape[1]}):")
        parts.append(grid_to_text(out))
        parts.append("")
    
    test_input = np.array(task_data['test'][0]['input'])
    parts.append(f"Test Input ({test_input.shape[0]}Ã—{test_input.shape[1]}):")
    parts.append(grid_to_text(test_input))
    
    parts.append("""
Task: Write a Python function `transform(grid: np.ndarray) -> np.ndarray` that implements the transformation rule.
Return only the function, using numpy/scipy.ndimage only.
""")
    
    return '\n'.join(parts)


def generate_hypothesis_verification_prompt(
    task_data: dict[str, Any],
    hypothesis: str,
    code: str,
    results: list[dict[str, Any]],
) -> str:
    """
    Generate a prompt for verifying/refining a specific hypothesis.
    
    Args:
        task_data: The task data
        hypothesis: The hypothesis being tested
        code: The code implementing the hypothesis
        results: Results from running the code on training examples
    
    Returns:
        Prompt for verification/refinement
    """
    parts = [
        "=" * 60,
        "HYPOTHESIS VERIFICATION",
        "=" * 60,
        "",
        f"HYPOTHESIS: {hypothesis}",
        "",
        "CODE:",
        "```python",
        code,
        "```",
        "",
        "RESULTS ON TRAINING EXAMPLES:",
    ]
    
    all_correct = True
    for i, result in enumerate(results):
        is_correct = result.get('correct', False)
        if not is_correct:
            all_correct = False
        
        status = "âœ“ CORRECT" if is_correct else "âœ— INCORRECT"
        parts.append(f"\n  Example {i + 1}: {status}")
        
        if not is_correct:
            expected_shape = result.get('expected_shape', '?')
            actual_shape = result.get('actual_shape', '?')
            parts.append(f"    Expected shape: {expected_shape}")
            parts.append(f"    Actual shape:   {actual_shape}")
            
            if result.get('error'):
                parts.append(f"    Error: {result['error']}")
            elif result.get('diff_count'):
                parts.append(f"    Mismatched cells: {result['diff_count']}")
    
    if all_correct:
        parts.append("\nâœ“ All examples pass! Apply to test input.")
    else:
        parts.append("\nâœ— Some examples fail. Refine your hypothesis.")
        parts.append("\nProvide:")
        parts.append("1. Analysis of what's wrong")
        parts.append("2. Refined hypothesis")
        parts.append("3. Corrected code")
    
    return '\n'.join(parts)
